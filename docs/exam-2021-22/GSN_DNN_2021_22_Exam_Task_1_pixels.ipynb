{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imporant pixels\n",
        "\n",
        "You are given a pipeline that trains a fully convolutional autoencoder on the MNIST dataset. The model should train in under 2 minutes and give decent results (mean reconstruction loss <35).\n",
        "\n",
        "Your task is to write a function that for a given input image and output pixel coordinates produces a list of input pixels that have non-zero contribution to the value of the output pixel. You should measure each pixel's contribution by setting it to the minimal and maximal value over the whole image.\n"
      ],
      "metadata": {
        "id": "5Z7Hz3cmGYlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training pipeline (DO NOT CHANGE THIS SECTION)"
      ],
      "metadata": {
        "id": "omLaGEc4aZHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import typing\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "OywVSurCbfNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 250\n",
        "learning_rate = 1e-2\n",
        "log_interval = 40"
      ],
      "metadata": {
        "id": "1Cd2k4MGbkkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Binarize:\n",
        "    def __call__(self, sample):\n",
        "        return torch.bernoulli(sample)\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    Binarize(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "train = MNIST('./data', train=True, transform=img_transform, download=True)\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test = MNIST('./data', train=False, transform=img_transform, download=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "PUCzv721bknZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FCN, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            1,\n",
        "            16,\n",
        "            kernel_size=(3, 3),\n",
        "            padding=1,\n",
        "            stride=1,\n",
        "            bias=False,\n",
        "        ),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(\n",
        "            16,\n",
        "            32,\n",
        "            kernel_size=(4, 4),\n",
        "            padding=1,\n",
        "            stride=2,\n",
        "            bias=False,),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(\n",
        "            32,\n",
        "            64,\n",
        "            kernel_size=(4, 4),\n",
        "            padding=1,\n",
        "            stride=2,\n",
        "            bias=False,),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                64,\n",
        "                32,\n",
        "                7,\n",
        "                2,\n",
        "                0,\n",
        "                bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                32,\n",
        "                16,\n",
        "                3,\n",
        "                1,\n",
        "                0,\n",
        "                bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                16,\n",
        "                8,\n",
        "                5,\n",
        "                1,\n",
        "                0,\n",
        "                bias=False),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(\n",
        "                8,\n",
        "                1,\n",
        "                4,\n",
        "                1,\n",
        "                0,\n",
        "                bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KpeNB3KhRTvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.mse_loss(output, data, reduction=\"sum\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item() / data.size(0)))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.mse_loss(output, data, reduction='sum').item()  # sum up batch loss\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n",
        "\n"
      ],
      "metadata": {
        "id": "1n09n8PVWpR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FCN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
        "    test(model, device, test_loader)\n"
      ],
      "metadata": {
        "id": "0I3woOWcSBPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important pixels"
      ],
      "metadata": {
        "id": "wg8A9DuMaT91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch = next(iter(train_loader))[0][0,:].unsqueeze(0)\n",
        "input_batch = input_batch.to(device)\n",
        "plt.imshow(input_batch[0, :].cpu().detach().squeeze().numpy())"
      ],
      "metadata": {
        "id": "N-QwwJ77jB3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(model(input_batch)[0, :].cpu().detach().squeeze().numpy())"
      ],
      "metadata": {
        "id": "mNf7bMGnaLUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def important_pixels(input_batch: torch.Tensor, model: torchvision.models.segmentation.fcn.FCN, device: torch.device, coordinates: typing.Tuple[int, int]) -> typing.Set[typing.Tuple[int,int]]:\n",
        "    model = model.to(device)\n",
        "    input_batch = input_batch.to(device)\n",
        "    ################################\n",
        "    # TODO: Find important pixels  #\n",
        "    ################################\n",
        "\n"
      ],
      "metadata": {
        "id": "T4xPxBueF7DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checked_pixel = (0, 0)\n",
        "pixels = important_pixels(input_batch, model, device, checked_pixel)"
      ],
      "metadata": {
        "id": "XDC6r9pzIWrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_numpy = input_batch[0, :].cpu().detach().squeeze().numpy()\n",
        "\n",
        "for pixel in pixels:\n",
        "    input_image_numpy[pixel[0], pixel[1]] = 0.25\n",
        "\n",
        "input_image_numpy[checked_pixel[0], checked_pixel[1]] = 0.75\n",
        "\n",
        "plt.imshow(input_image_numpy)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sDcpODGUkY1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nnLFi_E8oJtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}