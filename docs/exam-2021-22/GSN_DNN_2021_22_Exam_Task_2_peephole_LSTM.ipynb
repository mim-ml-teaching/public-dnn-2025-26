{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Peephole LSTM\n",
        "\n",
        "Given an implementation of an LSTM module:\n",
        "\\begin{align}\n",
        "i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
        "f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
        "g_t = tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{go}) \\\\\n",
        "o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
        "c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
        "h_t = o_t \\odot tanh(c_t)\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Your task is to modify the implementaiton to add [peephole connections](https://en.wikipedia.org/wiki/Long_short-term_memory#Peephole_LSTM) according to:\n",
        "\n",
        "\\begin{align}\n",
        "i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{ci} c_{t-1} + b_{ci}) \\\\\n",
        "f_t = \\sigma(W_{if} x_t + b_{if} + W_{cf} c_{t-1} + b_{cf}) \\\\\n",
        "o_t = \\sigma(W_{io} x_t + b_{io} + W_{co} c_{t-1} + b_{co}) \\\\\n",
        "c_t = f_t \\odot c_{t-1} + i_t \\odot tanh(W_{ic} x_t + b_{ic}) \\\\\n",
        "h_t = o_t \\odot c_t\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "dvCG1V_63yLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh3vt6p_3tUi"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, batch_first: bool):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        #input gate\n",
        "        self.W_ii = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_ii = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hi = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #forget gate\n",
        "        self.W_if = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_hf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_if = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hf = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #output gate c_t\n",
        "        self.W_ig = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_hg = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_ig = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hg = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #output gate h_t\n",
        "        self.W_io = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_io = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_ho = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self._init_parameters()\n",
        "\n",
        "    def _init_parameters(self):\n",
        "        for param in self.parameters():\n",
        "            torch.nn.init.normal_(param)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, hx: typing.Optional[typing.Tuple[torch.Tensor, torch.Tensor]] = None) -> typing.Tuple[torch.Tensor, typing.Tuple[torch.Tensor, torch.Tensor]]:\n",
        "\n",
        "        if not self.batch_first:\n",
        "            x = x.permute(1,0,2).contiguous()\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        sequence_length = x.size(1)\n",
        "\n",
        "        if hx is None:\n",
        "            h_t, c_t = (\n",
        "                torch.zeros(batch_size, self.hidden_size).to(x.device),\n",
        "                torch.zeros(batch_size, self.hidden_size).to(x.device),\n",
        "            )\n",
        "        else:\n",
        "            h_t, c_t = hx\n",
        "\n",
        "        output = []\n",
        "\n",
        "        for t in range(sequence_length):\n",
        "            x_t = x[:, t, :]\n",
        "            # input gate\n",
        "            i_t = torch.sigmoid(x_t @ self.W_ii + self.b_ii + h_t @ self.W_hi + self.b_hi)\n",
        "            # forget gate\n",
        "            f_t = torch.sigmoid(x_t @ self.W_if + self.b_if + h_t @ self.W_hf + self.b_hf)\n",
        "            # output gate\n",
        "            g_t = torch.tanh(x_t @ self.W_ig + self.b_ig + h_t @ self.W_hg + self.b_hg)\n",
        "            o_t = torch.sigmoid(x_t @ self.W_io + self.b_io + h_t @ self.W_ho + self.b_ho)\n",
        "\n",
        "            # output\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "            output.append(h_t.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat(output, dim=0)\n",
        "\n",
        "        if not self.batch_first:\n",
        "            output = output.permute(1,0,2).contiguous()\n",
        "\n",
        "        return output, (h_t, c_t)\n"
      ],
      "metadata": {
        "id": "zm4oIViI3xzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "a = torch.randn((5,10, 3))\n",
        "lstm = LSTM(3, 7, True)\n",
        "print(lstm(a)[0].size(), lstm(a)[1][0].size(), lstm(a)[1][1].size())\n",
        "print(lstm(a))"
      ],
      "metadata": {
        "id": "B6AeaQFWJUJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMPiphole(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, batch_first: bool):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        #input gate\n",
        "        self.W_ii = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_ci = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_ii = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_ci = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #forget gate\n",
        "        self.W_if = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_cf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_if = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_cf = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #output gate c_t\n",
        "        self.W_ic = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.b_ic = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "\n",
        "        #output gate h_t\n",
        "        self.W_io = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.W_co = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_io = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_co = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self._init_parameters()\n",
        "\n",
        "    def _init_parameters(self):\n",
        "        for param in self.parameters():\n",
        "            torch.nn.init.normal_(param)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, hx: typing.Optional[typing.Tuple[torch.Tensor, torch.Tensor]] = None) -> typing.Tuple[torch.Tensor, typing.Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        #################################\n",
        "        # TODO: Implement forward pass  #\n",
        "        #################################\n",
        "        pass"
      ],
      "metadata": {
        "id": "tk9w7qtsOZGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "a = torch.randn((5,10, 3))\n",
        "lstm = LSTMPiphole(3, 7, True)\n",
        "print(lstm(a)[0].size(), lstm(a)[1][0].size(), lstm(a)[1][1].size())\n",
        "print(lstm(a))"
      ],
      "metadata": {
        "id": "uAccfEBPyVC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}