{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Rotated MNIST\n",
        "\n",
        "In this task you will use MNIST dataset. The images are 28x28 and they are **rotated** by an angle from the range (-100, 100).  \n",
        "You are given a pipeline that trains a multi-head convolutional neural network on this dataset. The first head of the model performs a digit classification and the second head tries to predict the angle that the digit was rotated by.\n",
        "\n",
        "Your task is to:\n",
        "1. **(5 pts)** Implement CNN with classification and regression heads.\n",
        "2. **(3 pts)** Implement the model's loss - select appropriate loss functions for both heads and combine them into final loss of the model.\n",
        "3. **(3 pts)** Check the model's predictions on the test data and find for which classes the model achieves the best/worst performance both for classification and regression. Then, write a short explanation for the observed model behavior (why does the model have a problem with particular classes?).\n",
        "\n",
        "Hints:\n",
        "- You don't need to create a very sophisticated model - a few convolutions for CNN and a few linear layers for heads should be enough. After a few epochs the model should achieve classification accuracy above 90% and regression MAE below 18 on a test dataset.\n",
        "- When training multi-head models it is usually good to scale losses from particular heads so that they have similar contribution towards the final loss."
      ],
      "metadata": {
        "id": "LVqkfF75J0R2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JClziCgutliV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_blocks = torch.nn.Sequential(\n",
        "            ################## TODO ####################\n",
        "            # Subtask 1: Implement CNN architecture\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        self.classification_head = torch.nn.Sequential(\n",
        "            ################## TODO ####################\n",
        "            # Subtask 1: Implement classification head\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        self.regression_head = torch.nn.Sequential(\n",
        "            ################## TODO ####################\n",
        "            # Subtask 1: Implement regression head\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ################## TODO ####################\n",
        "        # Subtask 1: Implement forward\n",
        "        return log_probs, angle\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, (target_digit, target_angle)) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target_digit, target_angle = target_digit.to(device), target_angle.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        log_probs, angle = model(data)\n",
        "        ################## TODO ####################\n",
        "        # Subtask 2: Implement classification and regression loss, then combine them into\n",
        "        # final model loss\n",
        "        classification_loss = # TODO\n",
        "        regression_loss = # TODO\n",
        "        loss = # TODO\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                100. * (batch_idx + 1) / len(train_loader), loss.item()\n",
        "            ))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    abs_error = 0\n",
        "    with torch.no_grad():\n",
        "        for data, (target_digit, target_angle) in test_loader:\n",
        "            data = data.to(device)\n",
        "            target_digit, target_angle = target_digit.to(device), target_angle.to(device)\n",
        "            log_probs, angle = model(data)\n",
        "            ################## TODO ####################\n",
        "            # Subtask 2: Implement classification and regression loss, then combine them into\n",
        "            # final model loss (use the same loss as for training)\n",
        "            # Hint: pass reduction='sum' to loss functions to output loss correctly when logging\n",
        "            classification_loss = # TODO\n",
        "            regression_loss = # TODO\n",
        "            test_loss += # TODO\n",
        "            pred_digit = log_probs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred_digit.eq(target_digit.view_as(pred_digit)).sum().item()\n",
        "            abs_error += (target_angle - angle).abs().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Classification accuracy: {}/{} ({:.0f}%), Regression MAE: {:.2f}\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset),\n",
        "        abs_error / len(test_loader.dataset)\n",
        "    ))"
      ],
      "metadata": {
        "id": "Xz9C7B2Tv7oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "test_batch_size = 1000\n",
        "epochs = 5\n",
        "lr = 3e-3\n",
        "seed = 1\n",
        "log_interval = 50\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "QC5KM-cxt1P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': batch_size}\n",
        "test_kwargs = {'batch_size': test_batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {\n",
        "        'num_workers': 1,\n",
        "        'pin_memory': True,\n",
        "        'shuffle': True\n",
        "    }\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)"
      ],
      "metadata": {
        "id": "PwIlnwvDt2Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTWithRotations(datasets.MNIST):\n",
        "    def __init__(self, *args, transform=None, target_transform=None, **kwargs):\n",
        "        super(MNISTWithRotations, self).__init__(*args, **kwargs)\n",
        "        self.rotation_angles = (torch.rand(len(self.data)) - 0.5) * 2 * 100\n",
        "        self.is_img_transforemed = [False] * len(self.data)\n",
        "        self.transformed_data = torch.zeros(*self.data.shape)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not self.is_img_transforemed[idx]:\n",
        "            transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Lambda(\n",
        "                    lambda x: transforms.functional.rotate(x, self.rotation_angles[idx].item())\n",
        "                ),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            ])\n",
        "            img = Image.fromarray(self.data[idx].numpy(), mode=\"L\")\n",
        "            self.transformed_data[idx] = transform(img)\n",
        "            self.is_img_transforemed[idx] = True\n",
        "\n",
        "        img = self.transformed_data[idx].unsqueeze(0)\n",
        "        target_digit = int(self.targets[idx])\n",
        "        target_angle = self.rotation_angles[idx]\n",
        "        return img, (target_digit, target_angle)"
      ],
      "metadata": {
        "id": "CL7FU_6oZ2Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNISTWithRotations('../data', train=True, download=True)\n",
        "test_dataset = MNISTWithRotations('../data', train=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)"
      ],
      "metadata": {
        "id": "VfHgG5Dat3MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "7CNhBO1rPOJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of model performance for particular classes"
      ],
      "metadata": {
        "id": "xLJrMND90hOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############## TODO ################\n",
        "# Subtask 3: Check the model's predictions on the test data and find for which classes the\n",
        "# model achieves the best/worst performance both for classification and regression.\n",
        "# Write short explanation for observed behavior"
      ],
      "metadata": {
        "id": "-sG13o6HcKPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3Mf977ssXkg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}