{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1ghWaLRFSGR"
   },
   "source": [
    "# Patch pooling (10pts)\n",
    "Your task is to implement patch pooling. Patch pooling takes an input sequence $(a_0, a_1, \\ldots, a_{B-1})$ of $D$-dimensional embeddings and output an output sequence $(b_0, \\ldots, b_{k-1})$ of $D$-dimensional embeddings. The length of the output sequence is not longer than the length of the input sequence and is bounded by $P$. Each element of the input sequence is called a token. Each element of the output sequence is called a patch. Consecutive patches are constructed as a mean pooling of consecutive contiguous token spans.\n",
    "\n",
    "You are given two tensors:\n",
    "1. `batch` - a $3$-dimensional tensor, which is an input to a standard transformer model with the following dimensions:\n",
    "* B - batch size\n",
    "* S - sequence lenght\n",
    "* D - dimension of embedding of a single token\n",
    "\n",
    "`batch[x,y,:]` is the embedding of the $y+1$-th token of the $x+1$-th sequence in the `batch`.\n",
    "\n",
    "2. `patch_lengths` - $2$-dimensional integer-valued tensor with the following dimensions:\n",
    "* B - batch size\n",
    "* P - maximal number of patches\n",
    "\n",
    "`patch_lengths[x,y]` is the number of tokens forming patch number $y+1$ in the $x+1$-th sequence in the `batch`.\n",
    "\n",
    "The output should be a $3$-dimensional tensor with batch of sequences of patch embeddings.\n",
    "\n",
    "# Example\n",
    "The following snippet\n",
    "```python\n",
    "batch = torch.tensor([[[ 1.,  1.,  1.,  1.,  1.],\n",
    "         [ 1.,  1.,  1.,  1.,  1.],\n",
    "         [ 1.,  1.,  1.,  1.,  1.],\n",
    "         [ 2.,  2.,  2.,  2.,  2.],\n",
    "         [ 3.,  3.,  3.,  3.,  3.],\n",
    "         [ 3.,  3.,  3.,  3.,  3.]],\n",
    "\n",
    "        [[ 4.,  4.,  4.,  4.,  4.],\n",
    "         [ 4.,  4.,  4.,  4.,  4.],\n",
    "         [ 4.,  4.,  4.,  4.,  4.],\n",
    "         [ 4.,  4.,  4.,  4.,  4.],\n",
    "         [ 5.,  5.,  5.,  5.,  5.],\n",
    "         [-1., -1., -1., -1., -1.]],\n",
    "\n",
    "        [[ 6.,  6.,  6.,  6.,  6.],\n",
    "         [-1., -1., -1., -1., -1.],\n",
    "         [-1., -1., -1., -1., -1.],\n",
    "         [-1., -1., -1., -1., -1.],\n",
    "         [-1., -1., -1., -1., -1.],\n",
    "         [-1., -1., -1., -1., -1.]]])\n",
    "patch_lengths = torch.tensor([[3, 1, 2],\n",
    "        [4, 1, 0],\n",
    "        [1, 0, 0]])\n",
    "patch_pooling = PatchPooling()\n",
    "output = patch_pooling(batch, patch_lengths)\n",
    "output\n",
    "```\n",
    "\n",
    "should ouptut\n",
    "\n",
    "```python\n",
    "torch.tensor([[[1., 1., 1., 1., 1.],\n",
    "         [2., 2., 2., 2., 2.],\n",
    "         [3., 3., 3., 3., 3.]],\n",
    "\n",
    "        [[4., 4., 4., 4., 4.],\n",
    "         [5., 5., 5., 5., 5.],\n",
    "         [-1., -1., -1., -1., -1.]],\n",
    "\n",
    "        [[6., 6., 6., 6., 6.],\n",
    "         [-1., -1., -1., -1., -1.],\n",
    "         [-1., -1., -1., -1., -1.]]])\n",
    "```\n",
    "\n",
    "Remarks:\n",
    "\n",
    "1. In this problem you can assume that embeddings of the padding token are vectors with all coordinates equal to $-1$.\n",
    "\n",
    "2. Solutions will be graded with unit tests. You are given a single test case, which will be a part of evaluation.\n",
    "\n",
    "3. Solutions not satisfying the below requirements will be graded up to 4pts:\n",
    "* You are not allowed to call custom python functions\n",
    "* You are not allowed to use Python loops\n",
    "* Your are not allowed to use any other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NPA3vycFSGV",
    "outputId": "ebfcf5d7-6b4c-4100-fbb2-d9e559c2bd10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_patch_pooling.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_patch_pooling.py\n",
    "\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "\n",
    "class PatchPooling(torch.nn.Module):\n",
    "    def forward(self, batch: torch.Tensor, patch_lengths: torch.Tensor) -> torch.Tensor:\n",
    "        B, S, D = batch.shape\n",
    "        B_1, P = patch_lengths.shape\n",
    "\n",
    "        assert B == B_1\n",
    "\n",
    "        ### Your code goes here ###\n",
    "\n",
    "        ###########################\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class TestPatchPooling:\n",
    "    @pytest.mark.parametrize(\n",
    "        \"batch,patch_lengths,expected_output\",\n",
    "        [\n",
    "            (\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        [\n",
    "                            [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [2.0, 2.0, 2.0, 2.0, 2.0],\n",
    "                            [3.0, 3.0, 3.0, 3.0, 3.0],\n",
    "                            [3.0, 3.0, 3.0, 3.0, 3.0],\n",
    "                        ],\n",
    "                        [\n",
    "                            [4.0, 4.0, 4.0, 4.0, 4.0],\n",
    "                            [4.0, 4.0, 4.0, 4.0, 4.0],\n",
    "                            [4.0, 4.0, 4.0, 4.0, 4.0],\n",
    "                            [4.0, 4.0, 4.0, 4.0, 4.0],\n",
    "                            [5.0, 5.0, 5.0, 5.0, 5.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                        ],\n",
    "                        [\n",
    "                            [6.0, 6.0, 6.0, 6.0, 6.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "                torch.tensor([[3, 1, 2], [4, 1, 0], [1, 0, 0]]),\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        [\n",
    "                            [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [2.0, 2.0, 2.0, 2.0, 2.0],\n",
    "                            [3.0, 3.0, 3.0, 3.0, 3.0],\n",
    "                        ],\n",
    "                        [\n",
    "                            [4.0, 4.0, 4.0, 4.0, 4.0],\n",
    "                            [5.0, 5.0, 5.0, 5.0, 5.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                        ],\n",
    "                        [\n",
    "                            [6.0, 6.0, 6.0, 6.0, 6.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                        ],\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    def test_forward(\n",
    "        self,\n",
    "        batch: torch.Tensor,\n",
    "        patch_lengths: torch.Tensor,\n",
    "        expected_output: torch.Tensor,\n",
    "    ) -> None:\n",
    "        # given\n",
    "        patch_pooling = PatchPooling()\n",
    "\n",
    "        # when\n",
    "        output = patch_pooling(batch=batch, patch_lengths=patch_lengths)\n",
    "\n",
    "        # then\n",
    "        assert torch.all(torch.isclose(output, expected_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tI__yScxFSGX",
    "outputId": "c64f7cf3-44c9-4f49-b395-3a1894e6ec9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: /content\n",
      "plugins: langsmith-0.3.2, typeguard-4.4.1, anyio-3.7.1\n",
      "collected 1 item                                                                                   \u001b[0m\n",
      "\n",
      "test_patch_pooling.py \u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.90s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest test_patch_pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bw9BVO4VFYki"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
