{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kJ7igKEtjW"
      },
      "source": [
        "# Task: saliency map via occlusion\n",
        "\n",
        "In this task, you have a trained classifier and want to identify which parts of an image most influenced its prediction for a specific class. A simple method for this is to occlude portions of the image and observe the decrease in the predicted class probability compared to the original image's probability.\n",
        "\n",
        "Create a heatmap of those occlusions:\n",
        "* Take the original image (168×224) and replace a square of size 20×20 centered at point (i,j) (and cropped to the image frame) with a value of your choice.\n",
        "* Pass the image through the network and calculate the drop in the probability of class `GOLDFISH_LABEL`.\n",
        "* Do this with overlapping squares, with centers that cover the whole image, on a grid with stride 10: ((0,0), (0,10), ..., (10,0), (10,10), ..., (170,230)).\n",
        "* Return the heatmap as a 2D np.array (of shape (18, 24)).\n",
        "\n",
        "This should run under 2 minutes on CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyzEytJjncyJ"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aLAXUumfTCkB"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "from typing import cast\n",
        "\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "\n",
        "GOLDFISH_LABEL = MobileNet_V2_Weights.DEFAULT.meta[\"categories\"].index(\"goldfish\")\n",
        "\n",
        "\n",
        "def get_image(\n",
        "    url: str = \"http://www.mimuw.edu.pl/~cygan/welonka.jpg\",\n",
        "    target_max_size: int = 224\n",
        ") -> Tensor:\n",
        "    \"\"\"Return image as tensor of shape (C=3, H, W), normalized values.\"\"\"\n",
        "    img = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
        "    transformations = v2.Compose([\n",
        "        v2.Resize(size=None, max_size=target_max_size),\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True),  # scale to 0..1\n",
        "        v2.Normalize(\n",
        "            mean=IMAGENET_DEFAULT_MEAN,\n",
        "            std=IMAGENET_DEFAULT_STD\n",
        "        ),\n",
        "    ])\n",
        "    return cast(Tensor, transformations(img))\n",
        "\n",
        "\n",
        "def tensor_to_pil(image: Tensor) -> PIL.Image.Image:\n",
        "    \"\"\"Convert normalized image tensor of shape (C, H, W) to PIL Image.\"\"\"\n",
        "    C, H, W = image.shape\n",
        "    image = image.detach().permute(1, 2, 0).clone()  # to (H, W, C)\n",
        "    image *= torch.tensor(IMAGENET_DEFAULT_STD)\n",
        "    image += torch.tensor(IMAGENET_DEFAULT_MEAN)\n",
        "    img = PIL.Image.fromarray((image.numpy() * 255).astype(np.uint8))\n",
        "    return img\n",
        "\n",
        "\n",
        "DEFAULT_DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def get_model(training: bool = False, device: str = DEFAULT_DEVICE) -> torch.nn.Module:\n",
        "    model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "    model.to(torch.device(device))\n",
        "    model.train(training)\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_heatmap(heatmap: np.ndarray) -> None:\n",
        "    plt.matshow(heatmap)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_heatmap_over_image(image: Tensor, heatmap: np.ndarray, stride: int = 10, zoom: float = 2.0) -> None:\n",
        "    \"\"\"Show heatmap over image.\"\"\"\n",
        "    C, H, W = image.shape\n",
        "    rows, cols = heatmap.shape\n",
        "\n",
        "    heatmap = heatmap - np.min(heatmap)\n",
        "    heatmap = heatmap / (np.max(heatmap) + 1e-8)\n",
        "    heatmap = plt.get_cmap(\"viridis\")(heatmap)\n",
        "    heatmap_image = PIL.Image.fromarray((heatmap * 255).astype(np.uint8))\n",
        "    heatmap_image = heatmap_image.resize((cols * stride, rows * stride), resample=PIL.Image.NEAREST)\n",
        "    heatmap_image = heatmap_image.crop((stride // 2, stride // 2, W + stride // 2, H + stride // 2))\n",
        "    result = PIL.Image.blend(tensor_to_pil(image).convert(\"RGBA\"), heatmap_image, alpha=0.8)\n",
        "    result = result.resize((int(W * zoom), int(H * zoom)))\n",
        "    display(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCEw_JFGnia5"
      },
      "source": [
        "## Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYzuFrZNIpHk"
      },
      "outputs": [],
      "source": [
        "def generate_heatmap(model: torch.nn.Module, image: Tensor, stride: int = 10, window: int = 20) -> np.ndarray:\n",
        "    # YOUR CODE STARTS HERE\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvZeJY1XnnWQ"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zY06qqijR0l"
      },
      "outputs": [],
      "source": [
        "image = get_image()\n",
        "model = get_model()\n",
        "heatmap = generate_heatmap(model, image)\n",
        "\n",
        "print(\"Shape\", heatmap.shape)\n",
        "plt.imshow(tensor_to_pil(image))\n",
        "plot_heatmap(heatmap)\n",
        "plot_heatmap_over_image(image, heatmap)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}