{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsPdgBWQn4Vb"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Programu Operacyjnego Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ-w7K4eu6SK"
      },
      "source": [
        "# Logistic regression\n",
        "\n",
        "In this exercise you will train a logistic regression model via gradient descent in two simple scenarios.\n",
        "\n",
        "The general setup is as follows:\n",
        "* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{0,1\\}$ is the target,\n",
        "* for a given $x$ we model the probability of $y=1$ by $h(x):=g(w^Tx)$, where $g$ is the sigmoid function: $g(z) = \\frac{1}{1+e^{-z}}$,\n",
        "* to find the right $w$ we will optimize the so called logarithmic loss: $J(w) = -\\frac{1}{n}\\sum_{i=1}^n y_i \\log{h(x_i)} + (1-y_i) \\log{(1-h(x_i))}$,\n",
        "* with the loss function in hand we can improve our guesses iteratively:\n",
        "    * $w_j^{t+1} = w_j^{t} - \\eta \\cdot \\frac{\\partial J(w)}{\\partial w_j}$\n",
        "\n",
        "* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt2z7CdJu6SQ"
      },
      "source": [
        "Let's start with the simplest example - linear separated points on a plane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg_d38Fou6SU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "# these parametrize the line\n",
        "a = 0.3\n",
        "b = -0.2\n",
        "c = 0.001\n",
        "\n",
        "# True/False mapping\n",
        "def lin_rule(x, noise=0.):\n",
        "    return a * x[0] + b * x[1] + c + noise < 0.\n",
        "\n",
        "# Just for plotting\n",
        "def get_y_fun(a, b, c):\n",
        "    def y(x):\n",
        "        return - x * a / b - c / b\n",
        "    return y\n",
        "\n",
        "lin_fun = get_y_fun(a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZEHHKP8u6Si"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "\n",
        "n = 500\n",
        "range_points = 1\n",
        "sigma = 0.05\n",
        "\n",
        "X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n",
        "y = [lin_rule(x, sigma * np.random.normal()) for x in X]\n",
        "\n",
        "print(X[:10])\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoTCKl3Yu6St"
      },
      "source": [
        "Let's plot the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc99EecDu6Sw"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# plotly has a problem with coloring boolean values, hence stringify\n",
        "# see https://community.plotly.com/t/plotly-express-scatter-color-not-showing/25962\n",
        "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
        "x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n",
        "fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq3J7fZpu6S4"
      },
      "source": [
        "Now, let's implement and train a logistic regression model. You should obtain accuracy of at least 96%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw-eg0x0u6S6"
      },
      "outputs": [],
      "source": [
        "################################################################\n",
        "# TODO: Implement logistic regression and compute its accuracy #\n",
        "################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BextVVMWu6TB"
      },
      "source": [
        "Let's visually asses our model. We can do this by using our estimates for $a,b,c$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odWHQD9Au6TE"
      },
      "outputs": [],
      "source": [
        "#################################################################\n",
        "# TODO: Pass your estimates for a,b,c to the get_y_fun function #\n",
        "#################################################################\n",
        "lin_fun2 = get_y_fun(...)\n",
        "\n",
        "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
        "x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n",
        "fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n",
        "fig.add_scatter(x=x_range, y=list(map(lin_fun2, x_range)), name='estimated border')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u43DFWVFu6TO"
      },
      "source": [
        "Let's now complicate the things a little bit and make our next problem nonlinear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNCns_WIu6TS"
      },
      "outputs": [],
      "source": [
        "# Parameters of the ellipse\n",
        "s1 = 1.\n",
        "s2 = 2.\n",
        "r = 0.75\n",
        "m1 = 0.15\n",
        "m2 = 0.125\n",
        "\n",
        "# 0/1 mapping, checks whether we are inside the ellipse\n",
        "def circle_rule(x, y, noise=0.):\n",
        "    return 1 if s1 * (x - m1) ** 2 + s2 * (y - m2) ** 2 + noise < r ** 2 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H91RdYcOu6Tb"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "\n",
        "n = 500\n",
        "range_points = 1\n",
        "\n",
        "sigma = 0.1\n",
        "\n",
        "X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n",
        "\n",
        "y = [circle_rule(x, y, sigma * np.random.normal()) for x, y in X]\n",
        "\n",
        "print(X[:10])\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1keKZp-su6Tl"
      },
      "source": [
        "Let's plot the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5qQnZLBu6Tr"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
        "\n",
        "xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), 0.003)\n",
        "ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), 0.003)\n",
        "contour =  go.Contour(\n",
        "        z=np.vectorize(circle_rule)(*np.meshgrid(xgrid, ygrid, indexing=\"ij\")),\n",
        "        x=xgrid,\n",
        "        y=ygrid\n",
        "    )\n",
        "fig.add_trace(contour)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMwKzVQZu6Tw"
      },
      "source": [
        "Now, let's train a logistic regression model to tackle this problem. Note that we now need a nonlinear decision boundary. You should obtain accuracy of at least 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcnc848fu6Tx"
      },
      "source": [
        "Hint:\n",
        "<sub><sup><sub><sup><sub><sup>\n",
        "Use feature engineering.\n",
        "</sup></sub></sup></sub></sup></sub>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPINtZzou6T0"
      },
      "outputs": [],
      "source": [
        "################################################################\n",
        "# TODO: Implement logistic regression and compute its accuracy #\n",
        "################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nYLJvI4u6T7"
      },
      "source": [
        "Let's visually asses our model.\n",
        "\n",
        "Contrary to the previous scenario, converting our weights to parameters of the ground truth curve may not be straightforward. It's easier to just provide predictions for a set of points in $R^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vn13Nfuu6T9"
      },
      "outputs": [],
      "source": [
        "h = .02\n",
        "\n",
        "xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), h)\n",
        "ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), h)\n",
        "\n",
        "xx, yy = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n",
        "X_plot = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "print(X_plot.shape)\n",
        "\n",
        "_X = np.concatenate([X_plot, X_plot**2], axis=1)\n",
        "\n",
        "preds = logistic_regression(_w, _b, _X)\n",
        "print(preds.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE_jWcRZu6UG"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
        "\n",
        "xx, yy = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n",
        "\n",
        "contour = go.Contour(z=preds.reshape(len(xgrid), len(ygrid)), x=xgrid, y=ygrid)\n",
        "fig.add_trace(contour)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrr0piFgn9jz"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
