{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt6ZsxXC-Enh",
        "jukit_cell_id": "3bbXhEGl0p"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ykx6csq-Enk",
        "jukit_cell_id": "MjFPoyxoBk"
      },
      "source": [
        "# Variational Autoencoders (VAE)\n",
        "\n",
        "In this lab excercise you will train a Variational AuteEncoder to learn the distribution of MNIST data. You will explore the latent space and learn how to generate new samples.\n",
        "\n",
        "No need for GPUs today, training should take ~1 minute on a Colab CPU.\n",
        "\n",
        "Some notation:\n",
        "* $x \\in \\{0,1\\}^{28\\times 28}$ are images (binarized MNIST, for simplicity)\n",
        "* $z \\in \\mathbb{R}^d$ are latent vectors.\n",
        "* $p_\\text{prior}(z)$ is a *prior* distribution over the latent space. We'll use the standard multivariate gaussian distribution $\\mathcal{N}(0,\\mathbb{I}^d)$.\n",
        "* $E(x)$ is the encoder that accepts images $x$ as input and outputs a distribution over the latent space.\n",
        "  * The produced distribution is denoted $q_\\phi(z|x)$.\n",
        "  * We'll use the multivariate gaussian $\\mathcal{N}(\\mu, \\text{diag}(\\sigma^2))$\n",
        "  * $\\phi$ are weights of the encoder network.\n",
        "  * $\\mu=\\mu_{\\phi}(x)$ and $\\sigma=\\sigma_{\\phi}(x) \\in \\mathbb{R}^d$ is what the encoder network outputs.\n",
        "* $D(z)$ is the decoder that accepts samples $z$ from the latent distribution and outputs a distribution over images.\n",
        "  * The produced distribution is denoted $p_\\theta(x|z)$.\n",
        "  * We'll use the product distribution of independent per-pixel Bernoulli variables $\\prod_{i,j \\in [28\\times 28]} \\text{Bern}(p_{i,j}(z))$.\n",
        "  * $\\theta$ are weights of the decoder network.\n",
        "  * $p_{i,j}(z) \\in [0,1]$ are the $28 \\times 28$ outputs of the decoder network.\n",
        "\n",
        "The loss, for a sample $x$ from the dataset, is:\n",
        "\n",
        "$$ELBO(x) = \\mathbb{E}_{z \\sim q(z|x)} \\big[\\log p_\\theta(x|z)\\big] - D_{KL}\\big(q_\\phi(z | x) || p_\\text{prior}(z)\\big).$$\n",
        "\n",
        "The first term is trained by sampling $z$ using the reparametrization trick so that gradients flow through $\\mathbb{E}_{z \\sim q(z|x)}$.\n",
        "\n",
        "The second term can be calculated analytically in our setup and is equal to:\n",
        "\n",
        "$$ D_{KL}\\big( \\mathcal{N}(\\mu, \\text{diag}(\\sigma^2))\\ ||\\ \\mathcal{N}(0, \\mathbb{I}^d) \\big) = \\sum_{i \\in [d]} \\frac12 \\big(\\sigma_i^2  - \\log(\\sigma_i^2) + \\mu_i^2 - 1 \\big).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bgSeDQL-Enl",
        "jukit_cell_id": "eFnuUizAVu"
      },
      "source": [
        "## Tasks\n",
        "1. Run the pipeline and verify that VAE is training and generating decent digit representation.\n",
        "2. Implement the `encode_and_sample()` method in the VariationalAutoEncoder class, which accepts an image $x$ as input and outputs samples from the posterior distribution $q_\\phi(z|x)$.\n",
        "3. Implement the `decode_and_sample()` method in the VariationalAutoEncoder class, which accepts either samples $z_0$ or a number of samples to take from the prior distribution, and outputs sampled images $x$:\n",
        "    * If samples are not provided, take a sample $z_0 \\sim p(z)$ from the prior distribution.\n",
        "    * Run the decoder to obtain parameters $D_\\theta(z_0) = (p_{i,j}) \\in [0,1]^{28 \\times 28}$  describing the distribution $p_\\theta(x|z_0)$.\n",
        "    * Sample a reconstruction from that distribution: $x_0 \\sim p_\\theta(x|z_0)$.\n",
        "5. Explore the latent space. For each class (digit), encode a sample (≥100) of images $x$ of that class and visualize e.g. the first two parameters $\\mu_0, \\mu_1$ describing the distribution $q_\\phi(z|x)$. Visualize samples as scatter plot. Remember to color points according to image classes! Can you think of better ways to visualize it?\n",
        "6. Sample two points $z_0, z_1$ from the prior distribution $p(z)$. Perform an interpolation, i.e. visualize how samples change based on points from the segment between $z_0$ and $z_1$.\n",
        "    Can you think of other things to interpolate between?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtW-eI3KtfA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oaegYX3-Enm",
        "jukit_cell_id": "mIRhZXmXjZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.accelerator\n",
        "import torchvision.datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgPAiduKtfB"
      },
      "source": [
        "## Datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG4DPj87-Enn",
        "jukit_cell_id": "o6ghXwN1P4",
        "outputId": "8c5e1d1c-63da-4971-8d19-5dd4860c7fb0"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024\n",
        "test_batch_size = 1000\n",
        "\n",
        "latent_size = 5  # Dimensionality of the latent space (size of z vector).\n",
        "\n",
        "seed = 1\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KibO9W6lKtfD",
        "outputId": "2249b9e8-9397-445a-aaad-da886311314e"
      },
      "outputs": [],
      "source": [
        "# Check for CUDA / MPS (Apple) / XPU (Intel) / ... accelerator.\n",
        "device = (\n",
        "    torch.accelerator.current_accelerator(check_available=True)\n",
        "    or torch.device(\"cpu\")  #\n",
        ")\n",
        "use_accel = device != torch.device(\"cpu\")\n",
        "print(use_accel, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmixkxQsKtfE",
        "outputId": "fa663327-7c01-4870-b2c6-92de2a3811c2"
      },
      "outputs": [],
      "source": [
        "class RandomBinarize:\n",
        "    \"\"\"Input: tensor probabilities, output: samples (0 or 1), same shape, dtype bool.\"\"\"\n",
        "\n",
        "    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.bernoulli(sample).to(torch.bool)\n",
        "\n",
        "\n",
        "data_dir = Path(\"./data\")\n",
        "transform = v2.Compose(\n",
        "    [v2.ToImage(), v2.ToDtype(torch.float32, scale=True), RandomBinarize()]\n",
        ")\n",
        "inverse_transform = v2.Compose(\n",
        "    [\n",
        "        v2.ToDtype(torch.float32),\n",
        "        v2.ToDtype(torch.uint8, scale=True),\n",
        "        v2.ToPILImage(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    \"../data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\"../data\", train=False, transform=transform)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=use_accel,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=use_accel,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf4J54at-Eno",
        "jukit_cell_id": "DZ9ksDBfPV"
      },
      "outputs": [],
      "source": [
        "def visualize_data(\n",
        "    images: np.ndarray | Tensor,  # (B, C, H, W)\n",
        "    labels: np.ndarray | Tensor | None = None,  # (B,)\n",
        "    figsize: tuple[int, int] = (30, 30),\n",
        "):\n",
        "    B, C, H, W = images.shape\n",
        "    fig, axes = plt.subplots(1, B, figsize=figsize, squeeze=True, layout=\"constrained\")\n",
        "    if B == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i in range(0, B):\n",
        "        if C == 3:\n",
        "            axes[i].imshow(inverse_transform(images[i]))\n",
        "        else:\n",
        "            axes[i].imshow(inverse_transform(images[i].squeeze()), cmap=\"gray\")\n",
        "        if labels is not None:\n",
        "            axes[i].set_title(labels[i].item(), fontsize=28)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "WhYs_m9p-Eno",
        "jukit_cell_id": "lXKPRuseLX",
        "outputId": "7f222bd1-f807-42df-bfcb-7671971c62e5"
      },
      "outputs": [],
      "source": [
        "real_images, real_labels = next(iter(train_loader))\n",
        "visualize_data(real_images[:10], real_labels[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACBAnEclKtfF"
      },
      "source": [
        "## Models (encoder & decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K5QxQqT-Enp",
        "jukit_cell_id": "Hs9Xs1J7Tr"
      },
      "outputs": [],
      "source": [
        "class EncoderOutput(NamedTuple):\n",
        "    mu: Tensor  # mean of encoder output distribution, shape (B, latent_size)\n",
        "    sigma: Tensor  # standard deviations, shape (B, latent_size)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, linear_sizes: list[int], latent_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential()\n",
        "        for in_size, out_size in zip(linear_sizes[:-1], linear_sizes[1:], strict=True):\n",
        "            self.layers.append(nn.Linear(in_size, out_size))\n",
        "            self.layers.append(nn.BatchNorm1d(out_size))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        self.last_layer_mu = nn.Linear(linear_sizes[-1], latent_size)\n",
        "        self.last_layer_sigma = nn.Linear(linear_sizes[-1], latent_size)\n",
        "\n",
        "    def forward(self, x: Tensor) -> EncoderOutput:\n",
        "        \"\"\"Input x shape: (B, C, H, W) dtype bool, output: see EncoderOutput.\"\"\"\n",
        "        x = self.layers(x.flatten(start_dim=1).to(torch.float32))\n",
        "        mu = self.last_layer_mu(x)\n",
        "        logsigma = self.last_layer_sigma(x)\n",
        "        sigma = torch.log(1 + torch.exp(logsigma))  # softplus, make sure sigma > 0.\n",
        "        return EncoderOutput(mu=mu, sigma=sigma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J97S4jqt-Enp",
        "jukit_cell_id": "LHCziTTTb3"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, linear_sizes: list[int], output_size: tuple[int, int] = (28, 28)\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.layers = nn.Sequential()\n",
        "        for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n",
        "            self.layers.append(nn.Linear(in_layer_size, out_layer_size))\n",
        "            self.layers.append(nn.BatchNorm1d(out_layer_size))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        self.layers.append(nn.Linear(linear_sizes[-1], output_size[0] * output_size[1]))\n",
        "        self.layers.append(nn.Sigmoid())\n",
        "\n",
        "    def forward(self, z: Tensor) -> Tensor:\n",
        "        \"\"\"Input: z of shape (B, latent_size), output: Bernoulli probabilities 0..1 of shape (B, 1, H, W).\"\"\"\n",
        "        x = self.layers(z)\n",
        "        return x.view(-1, 1, *self.output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL8z4br0-Enp",
        "jukit_cell_id": "wuDJ1QVz4g"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoEncoderOutput(NamedTuple):\n",
        "    mu: Tensor  # (B, latent_size) means of z\n",
        "    sigma: Tensor  # (B, latent_size) standard deviations of z\n",
        "    p: Tensor  # (B, 1, H, W)  Bernoulli probabilities for reconstructed x.\n",
        "\n",
        "\n",
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder_linear_sizes: list[int],\n",
        "        latent_size: int,\n",
        "        decoder_linear_sizes: list[int],\n",
        "        output_size: tuple[int, int] = (28, 28),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(encoder_linear_sizes, latent_size)\n",
        "        self.decoder = Decoder(decoder_linear_sizes, output_size)\n",
        "        self.latent_size = latent_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        encoded = self.encoder(x)\n",
        "\n",
        "        eps = torch.normal(0.0, 1.0, size=encoded.mu.shape).to(device)\n",
        "        z = (eps * encoded.sigma) + encoded.mu\n",
        "\n",
        "        decoded = self.decoder(z)\n",
        "        return VariationalAutoEncoderOutput(\n",
        "            mu=encoded.mu, sigma=encoded.sigma, p=decoded\n",
        "        )\n",
        "\n",
        "    def encode_and_sample(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Input: x of shape (B, 1, H, W), output: z of shape (B, latent_size).\n",
        "        Output should be sampled in a way that allows for backpropagation.\n",
        "        \"\"\"\n",
        "        # TODO: Task 2.\n",
        "\n",
        "    def decode_and_sample(self, latents: Tensor | int) -> torch.Tensor:\n",
        "        \"\"\"Input: latents of shape (B, latent_size) or int (number of samples to generate from prior).\"\"\"\n",
        "        # TODO: Task 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6FRGyMqKtfG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIZUP2bk-Enp",
        "jukit_cell_id": "obLI7tPmnr"
      },
      "outputs": [],
      "source": [
        "def KL_gaussian_loss(mu: Tensor, sigma: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Input: mu and sigma of shape (B, latent_size), output: (B,).\n",
        "\n",
        "    The output is the KL divergence between N(mu, diag(sigma^2)) and N(0, 1).\n",
        "    \"\"\"\n",
        "    return torch.sum(\n",
        "        ((sigma * sigma) - (2 * torch.log(sigma)) + (mu * mu) - 1) / 2, dim=1\n",
        "    )\n",
        "\n",
        "\n",
        "def ELBO(x: Tensor, vae_output: VariationalAutoEncoderOutput) -> Tensor:\n",
        "    \"\"\"Input: x and VAE output. Returns: ELBO loss (scalar, mean over batch).\"\"\"\n",
        "    # Note that we sum over factors of factorial distribution, but take the mean over the batch.\n",
        "    BCE = (\n",
        "        F.binary_cross_entropy(vae_output.p, x.to(torch.float32), reduction=\"sum\")\n",
        "        / x.shape[0]\n",
        "    )\n",
        "    KL = KL_gaussian_loss(vae_output.mu, vae_output.sigma).mean()\n",
        "    return BCE + KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcJSq_n9-Enq",
        "jukit_cell_id": "AAjUQFvmUO"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    train_loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    epoch: int,\n",
        "    log_interval: int = 10,\n",
        ") -> None:\n",
        "    model.train()\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        vae_output = model(data)\n",
        "        loss = ELBO(data, vae_output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\n",
        "                f\"Train Epoch: {epoch} \"\n",
        "                + f\"[image {batch_idx * len(data)}/{len(train_loader.dataset)} ({batch_idx / len(train_loader):.0%})]\\t\"\n",
        "                + f\"Loss: {loss.item():.1f}\"\n",
        "            )\n",
        "\n",
        "\n",
        "def test(model: nn.Module, device: torch.device, test_loader: DataLoader) -> None:\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            vae_output = model(data)\n",
        "            loss = ELBO(data, vae_output)\n",
        "            test_loss += loss * data.shape[0]\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(f\"\\nTest set: Average loss: {test_loss:.1f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzMsb4hc-Enq",
        "jukit_cell_id": "MKcF1ppyPf"
      },
      "outputs": [],
      "source": [
        "vae = VariationalAutoEncoder(\n",
        "    [28 * 28, 500, 350], latent_size, [latent_size, 350, 500], (28, 28)\n",
        ")\n",
        "vae.to(device)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=5e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ3buFGYKtfH",
        "outputId": "e3ebb107-323f-4d69-b4cd-b1cf66283bed"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(vae, device, train_loader, optimizer, epoch)\n",
        "    test(vae, device, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9G-AmdFKtfH"
      },
      "source": [
        "## Results\n",
        "### Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VmYu1jCv-Enq",
        "jukit_cell_id": "RH7wUBm6oj",
        "outputId": "e0e0693a-2634-48f7-f637-468e2f32f75b"
      },
      "outputs": [],
      "source": [
        "def example_reconstruction():\n",
        "    real_images, real_labels = next(iter(train_loader))\n",
        "    real_images, real_labels = real_images[:8], real_labels[:8]\n",
        "    vae.eval()\n",
        "    vae_output = vae(real_images.to(device))\n",
        "    visualize_data(real_images.to(float).detach().cpu().numpy(), real_labels.cpu().numpy())\n",
        "    visualize_data(vae_output.p.detach().cpu().numpy())\n",
        "    x = torch.bernoulli(vae_output.p)\n",
        "    visualize_data(x.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "example_reconstruction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fSGpgg-Enr",
        "jukit_cell_id": "pZWX6YQi5T"
      },
      "source": [
        "### Visualization of latent space (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNxi1vZSKtfI"
      },
      "source": [
        "#### Scatterplot of encodings of real images (colored by class (digit))\n",
        "Hints: \n",
        "* Use `cmap=\"Paired\"` to get colors that are easy to distinguish.\n",
        "* Use `ax.legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\")` to show a legend with all 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClpmI-wN-Enr",
        "jukit_cell_id": "SFTCNxpj0s"
      },
      "source": [
        "#### Interpolation in latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "zrElBUtB-Enr",
        "jukit_cell_id": "D8W8xnsh8K",
        "outputId": "b7acc659-992a-4034-ff78-2f4756a65d6a"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "# TODO\n",
        "# generate images\n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "ims = [\n",
        "    [plt.imshow(inverse_transform(img.squeeze()), cmap=\"gray\", animated=True)]\n",
        "    for img in images\n",
        "]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=30, repeat_delay=1000, blit=True)\n",
        "plt.close()\n",
        "HTML(ani.to_jshtml())"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "colab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
